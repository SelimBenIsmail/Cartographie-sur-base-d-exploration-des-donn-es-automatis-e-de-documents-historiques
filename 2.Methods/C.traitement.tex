\section{Traitement de l'information}
%intro%
Les phases de traitement de l'information reprennent les opérations qui, d'une manière ou d'une autre, analysent ou modifient le contenu original du document source ou des informations extraites. Il peut s'agir d'audit de la qualité des informations contenues dans un tableau, de la mise en place de contraintes d'intégrité, de corrections de données ou encore de regroupements de données. 
L'objectif des opérations de traitement de l'information est d'améliorer la qualité des données extraites afin qu'elles soient utilisables dans les phases d'exploitation des données décrites dans la section suivante.

\subsection{Analyse de la qualité des données}
% définition des critères de qualité
S'il n'existe pas de consensus sur la définition même de ce que représente la qualité des données, pour autant, nous pouvons nous accorder à dire que la qualité des données se décompose en une pluralité de critères dont la pertinence et le poids varient selon le cadre d'utilisation des informations \parencite{berti-equille_qualite_2004}. De ce constat, est né le concept \textit{fitness for use} qui dit que :
\begin{displayquote}
    \og La qualité de l'information ne renvoie jamais à la perfection de celle-ci, mais à son adéquation relative à un ensemble de besoins donnés. La tolérance à l'erreur variera en fonction des enjeux.\fg{} 
    \footfullcite[p.7]{boydens_delivrable_2007} 
\end{displayquote} 
\vspace{0,5cm}

%enjeux de la qualité dans les process automatisés
Cette qualité des données est un aspect critique dans tout processus d'automatisation. C'est particulièrement vrai lorsque plusieurs opérations automatisées se succèdent sans vérification de l'agent humain. De petites erreurs en début de processus peuvent alors se propager et prendre de l'ampleur à travers chacune des étapes suivantes. 

%exemple
Si, par exemple, à la suite d'une erreur, une escroete n'est pas détectée par l'algorithme de segmentation et n'est, de facto,  pas non plus répertoriée. De cette seule erreur, il découlerait qu'aucune connétablie située au sein de l'escroete ne serait alors répertoriée. Par extension, toutes les rentes situées dans ces connétablies seraient également non indexées et omises dans la suite du processus. Ainsi, une unique erreur peut finalement lourdement impacter les résultats obtenus en sortie du système.

%stratégie globale 
Afin d'éviter cela, des audits de la qualité des données récoltées ont été menés pendant la conception du système. En fonction des résultats rendus, les algorithmes ont été corrigés afin d'intégrer des contraintes d'intégrité (approche préventive) et des opérations de nettoyages des données(approche curative).
Dans le cas d'un système qui serait alimenté par des flux de données nouvelles, les phases d'audit devraient être intégrées au système lui-même ; nous parlerions alors de \textit{gestion des processus} \parencite{berti-equille_qualite_2004}. Mais, dans le contexte qui est le nôtre, les données sont finies, plus aucune nouvelle entrée ne sera ajoutée au registre de rentes, nous pouvons donc sortir les phases d'audit du fonctionnement du système et les cantonner au développement du système.

\subsection{Nettoyage et correction des données}
%définition 
Le nettoyage des données est un processus d'amélioration des données qui a pour but, au travers d'une série de transformations, de normaliser les données et de détecter lorsque plusieurs enregistrements font référence à un même objet (phénomène de sur couverture) \parencite{berti-equille_qualite_2004}.

%stratégie de nettoyage %
Les stratégies pour la correction des données erronées sont aussi diverses que les causes qui les engendrent. C'est pour cela qu'avant toute chose, il est impératif de comprendre la nature du document source et des données qu'il contient. Il faut pouvoir supposer les différents facteurs qui auraient pu altérer l'information lors de son inscription dans le document source afin de mettre en place les vérifications nécessaires pour les anticiper, et le cas échéant, les corriger.

%Analyse du document et des données
Dans notre cas, si nous analysons \og l'histoire \fg{} du document source, nous pouvons dire qu'il s'agit d'un document texte au format \textit{.docx} qui  a été converti au format \textit{.txt}. Or, le format \textit{.docx} prend en charge des éléments d'édition de texte qui ne le sont pas dans les fichiers \textit{.txt}. Nous pouvons donc prévoir des erreurs liées à la perte d'informations engendrée par la conversion du fichier dans un format plus basique. 
Ce document \textit{.docx} est une retranscription d'une partie du livre de G. Espinas \textit{OCRisé}, qui lui-même retranscrit le registre original de Jean de France. Aux erreurs provenant du changement de format du document, nous pouvons donc aussi ajouter d'éventuelles erreurs de typographie ou d'\textit{OCR} \parencite{berti-equille_qualite_2004}.
Quant aux données contenues dans le document, elles sont de nature textuelle en langue picarde du XIIIe siècle. Du fait de cette particularité, les outils de nettoyage classiques sont inefficients. À l’instar de la reconnaissance d'entités nommées, il faut dans notre cas retourner à une approche plus élémentaire, qui s'appuie sur une reconnaissance morphologique des mots à l'aide d'expressions régulières. 

%doublons%
Une autre source de la perte de qualité de l'information est la présence de doublon au sein des tableaux de données. Nous pouvons légitimement supposer qu'il n'y en a pas dans le registre original, étant donné que celui-ci aurait été écrit de la main d'un seul homme  et que chacune des entrées du registre est classée selon un ordre topographique administratif avec un identifiant unique \parencite{espinas_les_1933}. Cependant, la possibilité que des doublons soient produits par les opérations automatisées de segmentation et de traitement n’est pas à négliger \parencite{koudoro-parfait_reconnaissance_2022}. Une vérification et une correction automatique sont donc effectuées après le remplissage de chaque tableau de données.

\subsection{Regroupement des données}
%définition %add ref
Le regroupement des données entre dans les stratégies courantes de détection et nettoyage des doublons. Elle fait donc, par définition, partie des opérations de nettoyage des données. Comme son nom l'indique, le regroupement de données va regrouper et fusionner les enregistrements d'un tableau de données  partageant de fortes similitudes entre eux et référençant un objet identique. 

% contexte
S'il est assez peu probable qu'il y ait des doublons au sein des rentes pour les raisons déjà énoncées, pour autant, il peut y en avoir dans le tableau où les entités nommées sont recensées. Ces doublons, dans ce cas précis, ne proviennent pas de négligence lors de l'enregistrement des données, ou d'erreurs  produites par les algorithmes, mais bien par des spécificités du contexte historique.
En effet, dans la langue du picard médiéval, les anthroponymes peuvent avoir de nombreuses variations de graphies ; un phénomène qui touche autant les noms de baptême que les patronymes.  Quatre raisons majeures à cela peuvent être citées.

%cause de la multiplicité des formes d'un anthroponymes 
Tout d'abord, les noms de baptême peuvent être déclinés en fonction de s'ils sont au \textit{cas sujet} ou au \textit{cas régime}. Le cas sujet et le cas régime sont des cas grammaticaux hérités du latin qui, aujourd'hui, ont disparu en tant que tels dans la langue française actuelle \parencite{kalm_roland_2009}.
Cette déclinaison se manifeste par l'ajout d'une \textit{marque casuelle} \og -s \fg{} au prénom. Ainsi, \og Joséphé \fg{} peut devenir \og Joséphés \fg{} si celui-ci est sujet. Toutefois, la présence de la marque n'est pas systématique dans les noms de personnes \parencite{mazziotta_marquage_2014}.
Ensuite, certains patronymes provenant de noms de métier ou de qualificatifs peuvent être dérivés au féminin lorsqu'ils sont portés par des femmes. Nous retrouvons par exemple dans le registre un << Druion Le Maçon >>, une << Margritain Le Maçonnesse >> et  une << Alis Le Maçone >> qui potentiellement viennent de la même famille, malgré que leurs patronymes ne soient pas exactement identiques. Également, la région n'étant pas exclusivement francophone, certains patronymes sont traduits, tantôt en picard, tantôt en flamand. Finalement, nous retrouvons de petites variations graphiques, sans doute dues à une certaine proximité phonétique \parencite{de_valeriola_lordinateur_2021}.

%méthode calcul de distance
La stratégie adoptée pour identifier les différentes variantes graphiques que peut prendre un même anthroponyme s'inspire, une nouvelle fois, des travaux de S. De Valeriola.

Une fois l'ensemble des anthroponymes recensé au sein d'une liste, la proximité morphologique entre chacun d'eux est calculée. Cette proximité morphologique entre deux anthroponymes est calculée selon le concept de \textit{distance d'édition}\footnote{Appelée aussi distance \textit{Levensthein}}. 
La distance d'édition entre deux chaînes de caractères est représentée par un score calculé en fonction du nombre d'opérations d'édition (suppression d'un caractère, insertion d'un caractère, substitution d'un caractère) nécessaires pour transformer une chaîne en l'autre. Il existe une multitude de distances différentes, reprenant la même idée, mais présentant chacune de légères spécificités. 
Dans notre cas, c'est la distance \textit{Damerau Levenshtein} qui a été retenue, car elle rajoute aux autres l'opération de transposition de deux caractères adjacents qui par la distance \textit{Levenshtein} était considérée comme deux opérations distinctes. 
À cette distance \textit{Damerau Levenshtein}, quelques modifications sur la pondération des différentes opérations ont été appliquées afin d'être plus juste quant aux spécificités de la langue picarde médiévale \parencite{de_valeriola_lordinateur_2021}.

%matrice 
Lorsque ces distances sont calculées, elles peuvent alors être représentées sous la forme d'une matrice. Cependant, la quantité de données  est telle, qu'il est impossible de regrouper les anthroponymes sur seule base de ce tableau (avec 798 anthroponymes recensés, il est question de 636804 combinaisons). Il est par conséquent nécessaire d'automatiser le processus de regroupement en définissant  un seuil de distance qui détermine quelles formes d'anthroponymes doivent être rassemblées dans le même groupe, et lesquelles ne doivent pas l'être. 

% choix de la distance seuil
Le choix de cette distance de seuil est une question particulièrement délicate et complexe qui a un impact  direct sur les résultats obtenus lors de l'exploitation des données. Si la distance seuil est trop haute, des anthroponymes risquent d'être intégrés à des groupes rassemblant des anthroponymes faisant référence à un autre personnage. Les résultats seront alors parasités par du \textit{bruit}. Ce bruit se concrétise par la fusion de sommets lors de la modélisation des graphes, ce qui créer de faux liens de mitoyenneté et déplacera également les sommets voisins, avec le risque d'une réaction en chaîne.
Au contraire, si la distance seuil est trop basse, certaines formes d'un anthroponyme risquent de ne pas être groupées avec les autres formes de variantes qui faisaient référence au même personnage. C'est du \textit{silence} qui est récolté dans ce cas. Il apparaît alors le phénomène inverse : au lieu que de multiples entités soient modélisées en un seul sommet, une entité unique se voit être modélisée en plusieurs sommets. Si le silence peut être relativement moins grave que le bruit dans notre cas --- dans le sens où il ne provoque pas de réactions en chaîne --- il engendre aussi des erreurs dans la modélisation des graphes. Il faut donc le réduire au possible.

%choix de la méthode 
Sur base du principe de calcul de distance précédemment évoqué, et au-delà du choix de la distance de seuil, il existe différentes méthodes d'application. Il peut être choisi de calculer la distance sur l'anthroponyme entier (nom de baptême et patronyme, ensemble, considéré comme une seule chaîne de caractère) ou sur les noms de baptême  et patronymes, chacun traité séparément, dans deux matrices différentes. En plus de cela, il est encore possible de modifier la pondération des opérations du  calcul des distances, à l'instar des modifications déjà apportées.

%ce qui a été décidé
En définitive, il a été décidé de calculer la distance sur l'entièreté de l'anthroponyme avec  une modification du poids de l'opération de substitution dans le calcul et de définir la distance de seuil à 3. 
Ces choix ont été déterminés par une série de tests destinés à observer la quantité de bruit récupérée avec les différentes méthodes. Ceux-ci seront plus amplement détaillés dans le chapitre \textit{Résultats}.

%remplacement dans le dataframe
Lorsque toutes les variantes graphiques de chaque anthroponyme sont recensées dans une liste par l'algorithme, cette dernière est alors vérifiée par l'agent humain. Si des erreurs sont remarquées au sein de la liste des groupes, en l'absence de solution pour une correction automatique, celles-ci sont corrigées manuellement.

La liste vérifiée, toutes les sections de rentes du tableau de données principal sont parcourues, et chaque fois qu'une forme variante d'un anthroponyme, ayant été préalablement listée, est rencontrée, cette dernière est remplacée par une forme généralisée de l'anthroponyme. 

\begin{figure} % insère une figure ici (h = "here")
    \centering
    \includegraphics[scale=0.75]{2.Methods/Img/clustering.drawio.pdf} 
    \caption{Organigramme de l'algorithme de regroupement des anthroponymes}
    \label{schemaClustering}
\end{figure}


